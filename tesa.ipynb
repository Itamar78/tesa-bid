{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8e70d-6685-4f6a-a610-832ce97eb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Requirements / environment (copy & run in shell if needed)\n",
    "# pip install -r requirements.txt\n",
    "# requirements.txt should include:\n",
    "# sentence-transformers==5.1.0\n",
    "# scikit-learn==1.2.2\n",
    "# pandas==2.1.0\n",
    "# numpy==1.25.0\n",
    "# joblib==1.3.1\n",
    "# fastapi==0.95.2\n",
    "# uvicorn==0.23.2\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef71b9fb-2eef-444b-9b76-f42f1cda1c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itamarlevi/my/py_envs/tesa_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Embedding model\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9cc774-d9e7-4f7b-b9c8-e17afb3e4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = Path('.') / 'input_files'\n",
    "BRIEF_PATH = DATA_DIR / 'brief.txt'\n",
    "LABELED_PATH = DATA_DIR / 'labeled_examples.csv'\n",
    "PAGES_PATH = DATA_DIR / 'pages.csv'\n",
    "TEST_PATH = DATA_DIR / 'test_set_1.csv'\n",
    "\n",
    "EMB_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "MIN_CPM = 0.5\n",
    "MAX_CPM = 6.0\n",
    "MODEL_PATH = Path('relevance_model.joblib')\n",
    "CALIBRATOR_PATH = Path('relevance_calibrator.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b92a6-4aaf-40f0-bf28-8472b1ff0491",
   "metadata": {},
   "source": [
    "<span style=\"font-size:30px;\">Utility functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b157712b-9acc-450f-8415-07ae12ec8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_text(path: Path) -> str:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "\n",
    "def compute_embeddings(model: SentenceTransformer, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "    return np.array(model.encode(texts, show_progress_bar=False, convert_to_numpy=True, batch_size=batch_size))\n",
    "\n",
    "\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray):\n",
    "    # a: (n, d) or (d,)\n",
    "    # b: (d,) or (m, d)\n",
    "    a_norm = a / np.linalg.norm(a, axis=-1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=-1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "\n",
    "def map_score_to_cpm(score: float, min_cpm=MIN_CPM, max_cpm=MAX_CPM) -> float:\n",
    "    # score in [0,1] -> linear map to [min_cpm, max_cpm]\n",
    "    return float(min_cpm + score * (max_cpm - min_cpm))\n",
    "\n",
    "\n",
    "def choose_threshold_by_f1(scores: np.ndarray, labels: np.ndarray) -> float:\n",
    "    precision, recall, thresholds = precision_recall_curve(labels, scores)\n",
    "    f1 = (2 * precision * recall) / (precision + recall + 1e-12)\n",
    "    best_idx = np.nanargmax(f1)\n",
    "    # precision_recall_curve returns thresholds of length len(precision)-1\n",
    "    if best_idx >= len(thresholds):\n",
    "        return 0.5\n",
    "    return float(thresholds[best_idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304501b-b493-4c25-8619-883cc6773b13",
   "metadata": {},
   "source": [
    "<span style=\"font-size:30px;\">Load Inputs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d49f44-d01d-4d2e-904a-188a4f92e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded brief (len=617 chars)\n",
      "labeled: (87, 3) pages: (158, 2) testset: (51, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert BRIEF_PATH.exists(), f\"Missing brief at {BRIEF_PATH}\"\n",
    "brief_text = read_text(BRIEF_PATH)\n",
    "print('Loaded brief (len=%d chars)' % len(brief_text))\n",
    "\n",
    "labeled = pd.read_csv(LABELED_PATH)\n",
    "pages = pd.read_csv(PAGES_PATH)\n",
    "testset = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print('labeled:', labeled.shape, 'pages:', pages.shape, 'testset:', testset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15ff82-6644-442d-9054-b7e6a2e0aa0b",
   "metadata": {},
   "source": [
    "<span style=\"font-size:30px;\">Initialize embedding model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef17c5a-be4b-4a74-9ad3-3e5927d12382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "print('Loading embedding model:', EMB_MODEL_NAME)\n",
    "emb_model = SentenceTransformer(EMB_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4835160e-3740-4a1e-87c0-f2765c72100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_snippets = list(pages['snippet'].fillna(''))  #   (158)  ['Stre…', 'Nurses rave about…', 'Review: n…',]\n",
    "snippet_embs = compute_embeddings(emb_model, all_snippets)  #(158, 384)  array([[-0.00971121,  0.00492362,  0.06036666, ..., -0.08424693,\n",
    "      #  -0.02608203,  0.04787878],\n",
    "      # [-0.04969076, -0.01702726, -0.02019079, ..., -0.00679669,\n",
    "      #  -0.01795055,  0.04061359]],dtype=float32)\n",
    "brief_emb = compute_embeddings(emb_model, [brief_text])[0]  # (384,)  array([-4.02793400e-02, -3.91791016e-03, -5.85291721e-02,], dtype=float32)\n",
    "\n",
    "sims = cosine_sim(snippet_embs, brief_emb).squeeze()  # (158,)  array([ 3.55501950e-01,  6.30325973e-01,  4.16991338e-02,  5.67493021e-01,] dtype=float32)\n",
    "\n",
    "# If you need normalized score in [0,1], rescale using min/max observed in the labeled set or pages\n",
    "sims_min, sims_max = sims.min(), sims.max()\n",
    "sims_norm = (sims - sims_min) / (sims_max - sims_min + 1e-12)  # (158,)  array([0.5689435 , 0.94204515, 0.1429241 , 0.856743  , 1 ] dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840a753b-869c-450c-80f6-85b335a7e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline tuned threshold (similarity normalized): 0.2919\n"
     ]
    }
   ],
   "source": [
    "# Baseline threshold tuning using labeled examples\n",
    "# From the labeled examples of each (cosine_score, label) pair, determine the optimal threshold.\n",
    "labeled_snippets = list(labeled['snippet'].fillna(''))  # (87) ['Str Week…', 'Nurses…', 'Review: n\"]\n",
    "labeled_embs = compute_embeddings(emb_model, labeled_snippets)  # (87, 384)\n",
    "labeled_sims = cosine_sim(labeled_embs, brief_emb).squeeze()  # (87,)  array([ 3.55501950e-01,  6.30325973e-01, ], dtype=float32)\n",
    "\n",
    "labeled_sims_norm = (labeled_sims - labeled_sims.min()) / (labeled_sims.max() - labeled_sims.min() + 1e-12) #(87) array([0.5689435 , 0.94204515, 0.1429241 , 0.85674)\n",
    "labels = labeled['label'].values  # 87  array([1, 1, 0, 1, 0, 1, 0, 1, 0, 1,])\n",
    "\n",
    "baseline_threshold = choose_threshold_by_f1(labeled_sims_norm, labels)\n",
    "print(f'Baseline tuned threshold (similarity normalized): {baseline_threshold:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47af8f83-283b-483e-96fa-5407f666492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map baseline scores to CPM\n",
    "baseline_prices = [map_score_to_cpm(s, MIN_CPM, MAX_CPM) for s in sims_norm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f047d7a-574a-49e9-b710-a4abddd8659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare baseline results DataFrame (for the 150 pages)\n",
    "# Apply the prediction using the threshold to the 150 pages.\n",
    "baseline_df = pages.copy()\n",
    "baseline_df['score'] = sims_norm\n",
    "baseline_df['bid'] = (baseline_df['score'] >= baseline_threshold).astype(int)\n",
    "baseline_df['price'] = baseline_df['score'].apply(lambda s: map_score_to_cpm(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528e331-f98d-42d2-aaa3-6637d18120af",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"font-size:30px;\">Learnable model: embeddings -> LogisticRegression</span><br>\n",
    "<span style=\"font-size:18px;\">Train Logistic regression on the labeled data</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc1441c1-7bc0-4d3f-932d-e12fbd395343",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labeled_embs\n",
    "y = labels\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c16b78f5-3d1a-4976-aa30-69d3f8087593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf22ae1-d2e8-46b8-9e9a-a9886928fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(cv=3,\n",
       "                       estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                    max_iter=1000,\n",
       "                                                    solver=&#x27;liblinear&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(cv=3,\n",
       "                       estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                    max_iter=1000,\n",
       "                                                    solver=&#x27;liblinear&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(cv=3,\n",
       "                       estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                    max_iter=1000,\n",
       "                                                    solver='liblinear'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calibration for better probability estimates\n",
    "calibrator = CalibratedClassifierCV(clf, method='sigmoid', cv=3)\n",
    "calibrator.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a90942a-7f68-4575-bfb1-776515443c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and calibrator\n"
     ]
    }
   ],
   "source": [
    "# Save model objects\n",
    "joblib.dump(clf, MODEL_PATH)\n",
    "joblib.dump(calibrator, CALIBRATOR_PATH)\n",
    "print('Saved model and calibrator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54dd9a-b1f0-45ea-83e3-ae57e6f10d2e",
   "metadata": {},
   "source": [
    "ROC the curve\n",
    "The AUC (Area Under the Curve) is a single number that summarizes the performance of the classifier across all possible thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e150aec3-456f-4637-97e7-d1ad66b2d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 1.0000, PR AUC: 1.0000, Acc: 94.44%\n"
     ]
    }
   ],
   "source": [
    "val_probs = calibrator.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_probs)\n",
    "# average precision focuses on the model's ability to find positive examples\n",
    "# average_precision_score is especially useful for highly imbalanced datasets where the positive class is rare. Unlike roc_auc_score\n",
    "val_ap = average_precision_score(y_val, val_probs)\n",
    "# Test using a threshold of 0.5, which we later realized was not optimal — the best threshold turned out to be 0.3.\n",
    "val_pred = (val_probs >= 0.5).astype(int)\n",
    "val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "print(f'Validation ROC AUC: {val_auc:.4f}, PR AUC: {val_ap:.4f}, Acc: {val_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da1e5a-ca5d-4b79-bb53-64fe6bfb2f88",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Find the optinal threshold</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b7367b0-135a-421f-bafe-236bd5c8c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned threshold (probability): 0.3544\n"
     ]
    }
   ],
   "source": [
    "# Choose threshold on the labeled set (using all labeled examples)\n",
    "all_probs = calibrator.predict_proba(X)[:, 1]\n",
    "learned_threshold = choose_threshold_by_f1(all_probs, y)\n",
    "print(f'Learned threshold (probability): {learned_threshold:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5d4d6-af9b-445e-8843-9e8a8161f03e",
   "metadata": {},
   "source": [
    "<span style=\"font-size:30px;\">Evaluate on test_set_1.csv</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2346665d-8010-4508-b83a-51c548b60983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute embeddings for test set\n",
    "test_snippets = list(testset['snippet'].fillna(''))\n",
    "test_embs = compute_embeddings(emb_model, test_snippets)\n",
    "\n",
    "# Two modes: baseline sims vs learned model probabilities\n",
    "# Baseline scores for test set\n",
    "test_sims = cosine_sim(test_embs, brief_emb).squeeze()\n",
    "test_sims_norm = (test_sims - sims_min) / (sims_max - sims_min + 1e-12)\n",
    "\n",
    "# Learned model probabilities for test set\n",
    "test_probs = calibrator.predict_proba(test_embs)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af5ec1fe-1b42-4ca7-80af-c8dd05704aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set performance:\n",
      "Baseline - Acc: 88.24%, ROC AUC: 0.9431, PR AUC: 0.9126\n",
      "Learned  - Acc: 100.00%, ROC AUC: 1.0000, PR AUC: 1.0000\n",
      "Wrote results.json (N=158)\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "test_labels = testset['label'].values\n",
    "\n",
    "\n",
    "# Baseline metrics (using baseline_threshold)\n",
    "baseline_test_pred = (test_sims_norm >= baseline_threshold).astype(int)\n",
    "baseline_acc = accuracy_score(test_labels, baseline_test_pred)\n",
    "baseline_auc = roc_auc_score(test_labels, test_sims_norm)\n",
    "baseline_ap = average_precision_score(test_labels, test_sims_norm)\n",
    "\n",
    "# Learned model metrics (using learned_threshold)\n",
    "learned_test_pred = (test_probs >= learned_threshold).astype(int)\n",
    "learned_acc = accuracy_score(test_labels, learned_test_pred)\n",
    "learned_auc = roc_auc_score(test_labels, test_probs)\n",
    "learned_ap = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "print('\\nTest set performance:')\n",
    "print(f'Baseline - Acc: {baseline_acc*100:.2f}%, ROC AUC: {baseline_auc:.4f}, PR AUC: {baseline_ap:.4f}')\n",
    "print(f'Learned  - Acc: {learned_acc*100:.2f}%, ROC AUC: {learned_auc:.4f}, PR AUC: {learned_ap:.4f}')\n",
    "\n",
    "pages_embs = compute_embeddings(emb_model, list(pages['snippet'].fillna('')))\n",
    "pages_probs = calibrator.predict_proba(pages_embs)[:, 1]\n",
    "\n",
    "pages_results = []\n",
    "for url, score in zip(pages['url'], pages_probs):\n",
    "    bid = int(score >= learned_threshold)\n",
    "    price = map_score_to_cpm(score)\n",
    "    pages_results.append({'url': url, 'bid': bid, 'price': round(price, 3), 'score': float(round(score, 4))})\n",
    "\n",
    "with open('results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(pages_results, f, indent=2)\n",
    "\n",
    "print('Wrote results.json (N=%d)' % len(pages_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
